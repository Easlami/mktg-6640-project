---
title: "EDA"
author: "Ethan Aslami"
date: "2025-06-10"
output: html_document
---


# Setup 

## Load Packages 
```{r}

warning(suppressMessages(library(tidyverse))) 
library(quanteda)
library(janitor)
library(here)
library(skimr)

```
## Load Data
```{r}

raw_reviews <- read_csv(here("group_project/top 240 restaurants recommanded in los angeles 2.csv")) %>% 
  clean_names()

# Create factor vars 
raw_reviews <- raw_reviews %>% 
  mutate(across(c(style, price), factor))

```


# EDA 

```{r}
# See data types and structure 
glimpse(raw_reviews)

summary(raw_reviews)
# Looks like we have a variety of reviews across many different styles of restaurants. 
# The most common type of restaurant is Korean with 2 variations of American restaurants following up. 


# Check data quality 
skim(raw_reviews)
# We are looking at a really clean dataset, there are hardly any issues with missing data and no duplicates

```


## Visualizations 

### Data Quality Checks
```{r}

# üßπ Data Quality Checks ------------------------------------------

# Count of missing values
sapply(raw_reviews, function(x) sum(is.na(x)))

# Check duplicated rows
number_of_dupes <- sum(duplicated(raw_reviews))
print(paste0("The number of duplicates is: ", number_of_dupes))

# Histogram: Outliers in number_of_reviews
ggplot(raw_reviews, aes(x = number_of_reviews)) +
  geom_histogram(binwidth = 100, fill = "#9999FF", color = "white") +
  labs(title = "Distribution of Number of Reviews", x = "Number of Reviews", y = "Count") +
  theme_minimal()

# Boxplot for star_rating to check for outliers
ggplot(raw_reviews, aes(y = star_rating)) +
  geom_boxplot(fill = "#FFCC99") +
  labs(title = "Star Rating Distribution", y = "Star Rating") +
  theme_minimal()


```


### General EDA 

```{r}

# 1. Histogram of Star Ratings
ggplot(raw_reviews, aes(x = star_rating)) +
  geom_histogram(binwidth = 0.1, fill = "#69b3a2", color = "white") +
  labs(title = "Distribution of Star Ratings", x = "Star Rating", y = "Count") +
  theme_minimal()



# 2. Line Chart of Reviews Over Time
raw_reviews %>%
  count(comment_date) %>%
  ggplot(aes(x = comment_date, y = n)) +
  geom_line(color = "#0073C2FF") +
  labs(title = "Number of Reviews Over Time", x = "Date", y = "Number of Reviews") +
  theme_minimal()


# 3. Average Star Rating by Price Tier
raw_reviews %>%
  filter(!is.na(price)) %>%
  group_by(price) %>%
  summarise(avg_rating = mean(star_rating, na.rm = TRUE)) %>%
  ggplot(aes(x = price, y = avg_rating, fill = price)) +
  geom_col() +
  labs(title = "Average Star Rating by Price Tier", x = "Price", y = "Avg. Star Rating") +
  theme_minimal() +
  theme(legend.position = "none")

# 4. Top 10 Most Reviewed Restaurants
raw_reviews %>%
  group_by(restaurant_name) %>%
  summarise(total_reviews = max(number_of_reviews)) %>%
  arrange(desc(total_reviews)) %>%
  slice_head(n = 10) %>%
  ggplot(aes(x = reorder(restaurant_name, total_reviews), y = total_reviews)) +
  geom_col(fill = "#FF6666") +
  coord_flip() +
  labs(title = "Top 10 Most Reviewed Restaurants", x = "Restaurant", y = "Total Reviews") +
  theme_minimal()

# 5. Average Star Rating by Style (Top 10)
raw_reviews %>%
  group_by(style) %>%
  summarise(avg_rating = mean(star_rating, na.rm = TRUE), n = n()) %>%
  arrange(desc(n)) %>%
  slice_head(n = 10) %>%
  ggplot(aes(x = reorder(style, avg_rating), y = avg_rating)) +
  geom_col(fill = "#66CC99") +
  coord_flip() +
  labs(title = "Average Rating by Style (Top 10)", x = "Style", y = "Avg. Rating") +
  theme_minimal()

# 6. Boxplot of Star Ratings by Price Tier
ggplot(raw_reviews, aes(x = price, y = star_rating, fill = price)) +
  geom_boxplot() +
  labs(title = "Star Ratings by Price Tier", x = "Price Tier", y = "Star Rating") +
  theme_minimal()

# 7. Number of Reviews by Price Tier (Bar Plot)
raw_reviews %>%
  group_by(price) %>%
  summarise(avg_reviews = mean(number_of_reviews, na.rm = TRUE)) %>%
  ggplot(aes(x = price, y = avg_reviews, fill = price)) +
  geom_col() +
  labs(title = "Average Number of Reviews by Price Tier", x = "Price Tier", y = "Avg. Number of Reviews") +
  theme_minimal()

# 7B. Total Number of Reviews by Price Tier (Bar Plot)
raw_reviews %>%
  group_by(price) %>%
  summarise(total_reviews = sum(number_of_reviews, na.rm = TRUE)) %>%
  ggplot(aes(x = price, y = total_reviews, fill = price)) +
  geom_col() +
  labs(title = "Total Number of Reviews by Price Tier", x = "Price Tier", y = "Avg. Number of Reviews") +
  theme_minimal()



```

### Detailed Visualizations 

```{r}

# üìä Rank-Based Analysis ------------------------------------------

# Categorize into rank groups
ranked_reviews <- raw_reviews %>%
  mutate(rank_group = case_when(
    rank <= 10 ~ "Top 10",
    rank <= 50 ~ "11‚Äì50",
    rank <= 100 ~ "51‚Äì100",
    rank <= 150 ~ "101‚Äì150",
    TRUE ~ "151‚Äì240"
  ))

# Average star rating by rank group
ranked_reviews %>%
  group_by(rank_group) %>%
  summarise(avg_rating = mean(star_rating, na.rm = TRUE)) %>%
  ggplot(aes(x = rank_group, y = avg_rating, fill = rank_group)) +
  geom_col() +
  labs(title = "Average Star Rating by Rank Group", x = "Rank Group", y = "Average Rating") +
  theme_minimal() +
  theme(legend.position = "none")

# Correlation between rank and reviews/star rating
ggplot(raw_reviews, aes(x = rank, y = number_of_reviews)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +
  labs(title = "Rank vs Number of Reviews", x = "Rank", y = "Number of Reviews") +
  theme_minimal()

ggplot(raw_reviews, aes(x = rank, y = star_rating)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "lm", se = FALSE, color = "darkgreen") +
  labs(title = "Rank vs Star Rating", x = "Rank", y = "Star Rating") +
  theme_minimal()


# üìç Location-Based Analysis ------------------------------------------

# Extract zip codes from address
raw_reviews <- raw_reviews %>%
  mutate(zip = str_extract(address, "\\d{5}"))

# Average rating by zip code
raw_reviews %>%
  group_by(zip) %>%
  summarise(avg_rating = mean(star_rating, na.rm = TRUE), n = n()) %>%
  filter(n >= 5) %>%  # Only zip codes with 5+ reviews
  ggplot(aes(x = reorder(zip, avg_rating), y = avg_rating)) +
  geom_col(fill = "#FF9966") +
  coord_flip() +
  labs(title = "Average Rating by Zip Code", x = "Zip Code", y = "Average Rating") +
  theme_minimal()


library(dplyr)
library(ggplot2)
library(tidyr)
library(forcats)

# üìà 1. Ratings 4.5 or Higher --------------------------------------

high_rated <- raw_reviews %>%
  filter(star_rating >= 4.5)

# Count of high-rated reviews by restaurant
high_rated_summary <- high_rated %>%
  group_by(restaurant_name) %>%
  summarise(n_reviews = n(),
            avg_rating = mean(star_rating),
            .groups = "drop") %>%
  arrange(desc(n_reviews))

# View top 10 high-rated restaurants by number of reviews
head(high_rated_summary, 10)

# üìä 2. Style of Top 25 Restaurants --------------------------------

# top 25 ordered by yelp's rank, not star rating 
top25_restaurants <- raw_reviews %>%
  group_by(restaurant_name) %>%
  summarise(
    avg_rating = mean(star_rating),
    n_reviews = n(),
    style = first(style),
    price = first(price),
    rank = min(rank),        # get best rank for restaurant
    .groups = "drop"
  ) %>%
  arrange(rank) %>%          # sort by rank ascending
  slice_head(n = 25)



# Clean up and split style into individual entries
top25_styles <- top25_restaurants %>%
  separate_rows(style, sep = ",\\s*") %>%
  count(style, sort = TRUE)

# Bar plot of most common styles
ggplot(top25_styles, aes(x = fct_reorder(style, n), y = n)) +
  geom_col(fill = "#66CC99") +
  coord_flip() +
  labs(title = "Most Common Styles in Top 25 Restaurants",
       x = "Style", y = "Count") +
  theme_minimal()

# üí≤ 3. Price Levels of Top 25 Restaurants -------------------------

top25_restaurants <- top25_restaurants %>%
  mutate(price = factor(price, levels = c("$$", "$$$", "$$$$")))

top25_prices <- top25_restaurants %>%
  count(price)

ggplot(top25_prices, aes(x = price, y = n, fill = price)) +
  geom_col(show.legend = FALSE) +
  labs(title = "Price Levels of Top 25 Restaurants",
       x = "Price Tier", y = "Count") +
  theme_minimal()


raw_reviews %>% 
  filter(style == str_detect("Korean")) %>% 
  group_by(restaurant_name) %>% 
  summarise(count = n(),
            star_rating = mean(star_rating),
            rank = mean(rank)) %>% 
  view()

raw_reviews %>% 
  filter(str_detect(style, "Korean")) %>% 
  group_by(restaurant_name) %>% 
  summarise(
    count = n(),
    star_rating = mean(star_rating, na.rm = TRUE),
    rank = mean(rank, na.rm = TRUE),
    number_of_reviews = mean(number_of_reviews)
  ) %>% 
  view()


unique(raw_reviews$style)

```





# Initial Text Analytics 

We decided to look into the some of the korean restaurants based on the EDA after seeing that there were a good sample group of them in the top 25 restaurants. 

Our New Goal is to 
- examine the restaurants in the top 25 and see what we can learn from reviews about how they are doing things better than their competitors
- Do a case study on a chosen restaurant or 2. We have a few options here 1 that is much lower on the ratings and another that is a middle of the pack restaurant. 
- We hope to provide insights to these restaurants as to how they can improve their restaurant experience to get higher ratings/get ranked higher by yelp

## filter to our subset of Korean Restaurants 
```{r}

# See the korean restaurants in the top 25 ranks 

# Low restaurants
raw_reviews %>% 
  filter(str_detect(style, "Korean")) %>% 
  filter(restaurant_name != "The Barn Cafe & Restaurant") %>% 
  group_by(restaurant_name) %>% 
  summarise(
    count = n(),
    star_rating = mean(star_rating, na.rm = TRUE),
    rank = mean(rank, na.rm = TRUE),
    number_of_reviews = mean(number_of_reviews)
  ) %>% 
  filter(rank > 150) %>% 
  arrange(rank) %>% 
  print() 

# High rated restaurants
top_korean_spots <- raw_reviews %>% 
  filter(str_detect(style, "Korean"),
         rank < 26)

# Low rated Korean Restaurants
bad_korean_spots <- raw_reviews %>% 
  filter(restaurant_name != "The Barn Cafe & Restaurant") %>% 
  filter(str_detect(style, "Korean"),
         rank > 150) 
```

## Positive Version 
```{r}
# Define custom words to remove
custom_stopwords <- c(stopwords("english"), "restaurant", "food", "great", "good", "place")

# Preprocessing
top_reviews_corpus <- corpus(top_korean_spots$comment)
top_reviews_tokens <- tokens(top_reviews_corpus, 
                             remove_punct = TRUE, 
                             remove_numbers = TRUE) %>%
  tokens_remove(custom_stopwords)

# Create a document-term matrix
top_reviews_dtm <- dfm(top_reviews_tokens)

# Inspect dimensions and preview a few rows of the DFM
dim(top_reviews_dtm)
head(top_reviews_dtm, n = 5)

library(quanteda.textstats)
tstat1 <- textstat_frequency(top_reviews_dtm)
head(tstat1, 10)

# Load textplots and visualize word frequencies as a word cloud
library(quanteda.textplots)
textplot_wordcloud(
  top_reviews_dtm,
  min_size = 0.5,
  max_size = 4,
  min_count = 3,
  max_words = 200,
  color = "darkblue",
  font = NULL,
  adjust = 0,
  rotation = 0.1,
  random_order = FALSE,
  random_color = FALSE,
  ordered_color = FALSE,
  labelcolor = "gray20",
  labelsize = 1.5,
  labeloffset = 0,
  fixed_aspect = TRUE,
  comparison = FALSE
)
```


## Combined Version 
```{r}
# Combine with group labels
combined_reviews <- bind_rows(
    bad_korean_spots %>% mutate(group = "Low Ranked"), 
    top_korean_spots %>% mutate(group = "Top Ranked")
)

# Create corpus
reviews_corpus <- corpus(combined_reviews, text_field = "comment")


tokens_reviews <- tokens(reviews_corpus,
                         what = "word",
                         remove_punct = TRUE,
                         remove_numbers = TRUE,
                         remove_symbols = TRUE) %>%
  tokens_tolower() %>%
  tokens_remove(custom_stopwords) %>%
  # tokens_wordstem(language = "english") %>%
  tokens_keep(min_nchar = 3) %>%
  tokens_ngrams(n = 1:2)

# Create a DFM grouped by sentiment
dfm_grouped <- dfm(tokens_reviews) %>%
  dfm_group(groups = docvars(reviews_corpus, "group"))

# Calculate TF-IDF
tfidf_df <- dfm_tfidf(dfm_grouped)

# Convert TF-IDF to a data.frame for interpretation
tfidf_df <- convert(tfidf_df, to="data.frame")


# Plot wordcloud
p <- textplot_wordcloud(
  dfm_grouped,
  comparison = TRUE,
  min_size = 0.5,
  max_size = 3,
  min_count = 5,
  max_words = 200,
  color = c("red", "darkgreen"),
  font = NULL,
  adjust = 0,
  rotation = 0.1,
  random_order = FALSE,
  random_color = FALSE,
  ordered_color = FALSE,
  labelcolor = "gray20",
  labelsize = 1.5,
  labeloffset = 0,
) 


```

```{r}

ggsave(p, "plot.png")
```


## XgBoost 

